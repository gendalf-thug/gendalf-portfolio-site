# Кеширование слоев и другие возможности docker

## Слои

**Слои** в Docker представляют собой логические шаги или состояния, используемые при создании образов контейнеров. Каждый слой представляет собой изменения или добавления в файловую систему образа.

![layers](./layers.png)

## Кеширование слоев

**Кеширование слоев** - это механизм, который позволяет Docker повторно использовать уже созданные слои образа при сборке новых образов или контейнеров. Вместо полной пересборки всего образа, Docker проверяет кэш для уже существующих слоев и использует их, если команды и инструкции в Dockerfile не изменились.

Лучшей практикой применения кеша Docker'а является кеширование пакетных зависимостей во время сборки Docker образов. Это особенно важно для языков программирования, которые используют менеджеры пакетов(npm для Node.js, pip для Python и др), чтобы управлять зависимостями проекта.

При использовании менеджеров пакетов в Dockerfile, рекомендуется сначала копировать файлы с описанием зависимостей (package.json, requirements.txt) в образ и установить зависимости до копирования остальных файлов проекта. Это позволяет Docker кешировать установку пакетов и не выполнять ее повторно при каждой сборке образа, если файлы зависимостей не изменились.

```dockerfile
# Копируем файлы с описанием зависимостей
COPY package.json package-lock.json ./

# Устанавливаем зависимости
RUN npm install

# Копируем остальные файлы проекта
COPY . .

# Остальные инструкции для сборки образа
...
```

## Multi-stage

**Multi-stage** - это методика использования нескольких этапов в Dockerfile для создания контейнеров. Она позволяет разделять этапы сборки приложения, где каждый этап выполняет свою задачу, а затем объединять только необходимые компоненты в итоговый образ. Это может значительно уменьшить размер итогового образа и уменьшить потребление ресурсов благодаря параллельному выполнению.

В Dockerfile этап сборки представлен инструкцией `FROM`

Примером использования разделения на этапы сборки и выполнения с помощью multi-stage может служить React приложение:

```dockerfile
# Этап 1: Базовый этап для установки зависимостей и сборки приложения
FROM node:18
WORKDIR /app
COPY package.json package-lock.json ./
RUN npm install
COPY . .
RUN npm run build

# Этап 2: Финальный этап с минимальным образом для запуска приложения
FROM nginx:alpine
COPY --from=0 /app/build /usr/share/nginx/html
EXPOSE 80
```

Файлы React проекта собираются в понятный html и js код для браузера. Это значит что для нас будет излишним иметь образ `node:18` в самом контейнере. Поэтому мы разделили инструкции `dockerfile` на 2 этапа. Каждый этап в Dockerfile имеет свой порядковый номер, начиная с 0. Как вы заметили, мы обращаемся к первому этапу с помощью флага `--from=0`(отсчет этапов начинается с нуля).

Что происходит в этапах?

1. Этап 1: Мы используем образ `node:18` в качестве базового для установки зависимостей. Затем мы копируем все остальные файлы из текущей директории и выполняем команду `npm run build`, чтобы собрать наше React приложение. Результатом этого этапа будет временный образ, содержащий скомпилированный код нашего React приложения.
2. Этап 2: Здесь мы используем легковесный образ `nginx:alpine` для доступа к React приложению через сеть. Мы копируем содержимое папки `build` из первого этапа в директорию `/usr/share/nginx/html`, которая является стандартным расположением для статических файлов, обслуживаемых Nginx. Затем мы открываем порт `80`, чтобы приложение было доступно извне контейнера.

Еще есть возможность создания псевдонимов для этапов с помощью инструкции `AS` и обращаться к ним уже по имени, а не порядковому во флаге `--from`. Это позволяет нам использовать более понятные имена вместо порядковых номеров, делая сборку Docker образа более ясной и поддерживаемой:

```dockerfile
FROM node:18 AS build
# ... Build processing

FROM nginx:alpine
COPY --from=build /app/build /usr/share/nginx/html
EXPOSE 80
```

### Параллелизм

**Параллелизм этапов** представляет собой процесс сборки Docker образов, в котором этапы, не зависящие друг от друга, выполняются параллельно и независимо друг от друга. Это позволяет оптимизировать время сборки образов и ускорить процесс разработки и развертывания контейнеризированных приложений. Важно помнить, что не все этапы можно выполнять параллельно, так как некоторые могут зависеть от результатов предыдущих этапов. Docker автоматически запускает этапы параллельно если это возможно.

Пример из документации docker:

```dockerfile
FROM golang:1.20-alpine AS base
WORKDIR /src
COPY go.mod go.sum .
RUN go mod download
COPY . .

FROM base AS build-client
RUN go build -o /bin/client ./cmd/client

FROM base AS build-server
RUN go build -o /bin/server ./cmd/server

FROM scratch
COPY --from=build-client /bin/client /bin/
COPY --from=build-server /bin/server /bin/
ENTRYPOINT [ "/bin/server" ]
```

## Несколько образов из одного Dockerfile

Можно создавать несколько разных образов с помощью одного Dockerfile. Вы можете указать нужный этап сборки(который будет включен в образ для исполнения программы), используя флаг `--target` в команде `docker build`. Это позволит избежать необходимости создавать оба двоичных ящика каждый раз.

Пример из документации docker, тут последний безыменный этап(с прошлого примера) был разделен на 2 этапа:

```dockerfile
FROM golang:1.20-alpine AS base
WORKDIR /src
COPY go.mod go.sum .
RUN go mod download
COPY . .

FROM base AS build-client
RUN go build -o /bin/client ./cmd/client

FROM base AS build-server
RUN go build -o /bin/server ./cmd/server

FROM scratch AS client
COPY --from=build-client /bin/client /bin/
ENTRYPOINT [ "/bin/client" ]

FROM scratch AS server
COPY --from=build-server /bin/server /bin/
ENTRYPOINT [ "/bin/server" ]
```

Теперь можно собирать образы:

```sh
docker build --tag=buildme-client --target=client .
docker build --tag=buildme-server --target=server .
```
